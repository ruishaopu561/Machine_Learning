{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: write a short paragraph to describe your understanding of \n",
    "# 　　image classification task. Also please include a plan (e.g., \n",
    "# 　　overall　system flowchart), expected outputs and anything you \n",
    "# 　　think it should be included.\n",
    "\n",
    "# Step 2: build a basic Alex net using tensorflow or pytorch from \n",
    "# 　　scratch. Train the net using CIFAR training data. Use Tensorboard\n",
    "# 　　to help visualize and analyze the training and testing procedure.\n",
    "\n",
    "# Step 3: Use pre-trained deep model (VGG or ResNet-18) to build image\n",
    "# 　　classification model, i.e., fine-tune with CIFAR dataset.  Use \n",
    "# 　　Tensorboard to help visualize and analyze the training and \n",
    "# 　　testing procedure.\n",
    "\n",
    "# Step 4: Analyse training/testing error and prepare the report for \n",
    "# 　　your observation and conclusion.\n",
    "\n",
    "# Again, the purpose of this mini-project is not the final results, \n",
    "# 　　but the whole procedure you work on this project. Please jog down\n",
    "# 　any problems you met, and your solutions or analysis if applicable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "dtype = torch.float32\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import sampler\n",
    "\n",
    "NUM_TRAIN = 48000\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "def getData(batch_size):\n",
    "    cifar10_train = dset.CIFAR10('../datasets/', train=True, download=True, transform=transform)\n",
    "    loader_train = DataLoader(cifar10_train, batch_size=batch_size,\n",
    "#                               sampler=sampler.SubsetRandomSampler(list(range(NUM_TRAIN, len(cifar10_train)))), \n",
    "                              num_workers=4)\n",
    "\n",
    "    cifar10_val = dset.CIFAR10('../datasets/', train=False, download=True, transform=transform)\n",
    "    loader_val = DataLoader(cifar10_val, batch_size=batch_size, \n",
    "#                             sampler=sampler.SubsetRandomSampler(list(range(7500,len(cifar10_val)))), \n",
    "                            num_workers=4)\n",
    "    \n",
    "#     print(\"batch_size\", batch_size)\n",
    "    print(\"loader_train:\", len(loader_train), \"loader_val:\", len(loader_val))\n",
    "    return (loader_train, loader_val)\n",
    "# getData(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0]\n",
    "    return x.view(N, -1)\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "channel_1 = 96\n",
    "channel_2 = 256\n",
    "channel_3 = 384 \n",
    "channel_4 = 384\n",
    "channel_5 = 256\n",
    "\n",
    "num_feature_1 = 96\n",
    "num_feature_2 = 256\n",
    "num_feature_3 = 384\n",
    "\n",
    "feature_1 = 6*6*256\n",
    "feature_2 = 2048\n",
    "feature_3 = 10\n",
    "\n",
    "def getModel():\n",
    "    return nn.Sequential(\n",
    "        \n",
    "    nn.Conv2d(in_channels=3, out_channels=96, kernel_size=3, stride=1, padding=2, bias=True),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(96),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    nn.Conv2d(in_channels=96, out_channels=256, kernel_size=3, stride=1, padding=2, bias=True),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "    nn.ReLU(),\n",
    "#     nn.BatchNorm2d(384),\n",
    "\n",
    "    nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "    nn.ReLU(),\n",
    "#     nn.BatchNorm2d(384),\n",
    "\n",
    "    nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    nn.Dropout(p=0.5, inplace=False),\n",
    "    nn.Linear(in_features=4096, out_features=feature_2),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.Dropout(p=0.5, inplace=False),\n",
    "    nn.Linear(in_features=feature_2, out_features=feature_2),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.Linear(in_features=feature_2, out_features=feature_3)\n",
    ")\n",
    "\n",
    "# model = nn.Sequential(\n",
    "\n",
    "#     nn.Conv2d(in_channels=3, out_channels=channel_1, kernel_size=(11, 11), stride=1, padding=(2, 2), bias=True),\n",
    "#     nn.ReLU(),\n",
    "# #     nn.BatchNorm2d(num_features=num_feature_1),\n",
    "#     nn.MaxPool2d(kernel_size=(3, 3), stride=2),\n",
    "\n",
    "#     nn.Conv2d(in_channels=channel_1, out_channels=channel_2, kernel_size=(5, 5), stride=1, padding=(2, 2), bias=True),\n",
    "#     nn.ReLU(),\n",
    "# #     nn.BatchNorm2d(num_features=num_feature_2),\n",
    "#     nn.MaxPool2d(kernel_size=(3, 3), stride=2),\n",
    "\n",
    "#     nn.Conv2d(in_channels=channel_2, out_channels=channel_3, kernel_size=(3, 3), stride=1, padding=(1, 1), bias=True),\n",
    "#     nn.ReLU(),\n",
    "# #     nn.BatchNorm2d(num_features=num_feature_3),\n",
    "\n",
    "#     nn.Conv2d(in_channels=channel_3, out_channels=channel_4, kernel_size=(3, 3), stride=1, padding=(1, 1), bias=True),\n",
    "#     nn.ReLU(),\n",
    "# #     nn.BatchNorm2d(num_features=num_feature_3),\n",
    "\n",
    "#     nn.Conv2d(in_channels=channel_4, out_channels=channel_5, kernel_size=(3, 3), stride=1, padding=(1, 1), bias=True),\n",
    "#     nn.ReLU(),\n",
    "# #     nn.BatchNorm2d(num_features=num_feature_2),\n",
    "#     nn.MaxPool2d(kernel_size=(3, 3), stride=2),\n",
    "\n",
    "#     Flatten(),\n",
    "    \n",
    "#     nn.Linear(in_features=feature_1, out_features=feature_2),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Dropout(p=0.5, inplace=False),\n",
    "\n",
    "#     nn.Linear(in_features=feature_2, out_features=feature_2),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Dropout(p=0.5, inplace=False),\n",
    "\n",
    "#     nn.Linear(in_features=feature_2, out_features=feature_3)\n",
    "# )\n",
    "# print(getModel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')\n",
    "\n",
    "    num_samples = 0\n",
    "    num_correct = 0\n",
    "    model.eval()\n",
    "    for x, y in loader:\n",
    "        x = x.to(device=device)\n",
    "        y = y.to(device=device)\n",
    "        scores = model(x)\n",
    "        _, preds = torch.max(scores, dim=1)\n",
    "        num_correct += (preds == y).sum()\n",
    "        num_samples += x.shape[0]\n",
    "    acc = float(num_correct) / num_samples\n",
    "    print('Got %d / %d correct (%.2f%%)\\n' % (num_correct, num_samples, 100 * acc))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(lr, bs, mo, epochs=100):\n",
    "    print(\"lr:\",lr, \" bs:\", bs, \" mo:\", mo)\n",
    "\n",
    "    loader_train, loader_val = getData(bs)\n",
    "\n",
    "    model = getModel()\n",
    "    optimizer = setOptim(model, learning_rate=lr, momentum=mo)\n",
    "\n",
    "    model = model.to(device=device)\n",
    "\n",
    "    writer = SummaryWriter(comment=\"1_epoch\")\n",
    "    train_len = len(loader_train)\n",
    "\n",
    "    images, labels = next(iter(loader_train))\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        epoch_count = 0\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "            optimizer.zero_grad() # 梯度归零\n",
    "            model.train()\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)  # 计算loss\n",
    "            loss.backward() #　反向传播\n",
    "            optimizer.step() # 更新参数\n",
    "\n",
    "            epoch_count += 1\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        writer.add_scalar('train', epoch_loss/epoch_count, e)\n",
    "#         writer.add_scalar('train', loss.item(), e*len(loader_train)+t)\n",
    "#         writer.add_graph(model, x)\n",
    "\n",
    "        print('epoch %d, loss = %.4f' %(e, epoch_loss/epoch_count))\n",
    "\n",
    "        acc = check_accuracy(loader_val, model)\n",
    "\n",
    "        if e % 20 == 0:\n",
    "            lr = lr/3.0\n",
    "            optimizer = setOptim(model, learning_rate=lr, momentum=mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setOptim(model, learning_rate, momentum):\n",
    "    return optim.SGD(model.parameters(), lr=learning_rate, momentum = momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001  bs: 64  mo: 0.9\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "loader_train: 782 loader_val: 157\n",
      "epoch 0, loss = 1.5172\n",
      "Checking accuracy on test set\n",
      "Got 5958 / 10000 correct (59.58%)\n",
      "\n",
      "epoch 1, loss = 1.0383\n",
      "Checking accuracy on test set\n",
      "Got 6467 / 10000 correct (64.67%)\n",
      "\n",
      "epoch 2, loss = 0.9134\n",
      "Checking accuracy on test set\n",
      "Got 6957 / 10000 correct (69.57%)\n",
      "\n",
      "epoch 3, loss = 0.8248\n",
      "Checking accuracy on test set\n",
      "Got 7168 / 10000 correct (71.68%)\n",
      "\n",
      "epoch 4, loss = 0.7455\n",
      "Checking accuracy on test set\n",
      "Got 7362 / 10000 correct (73.62%)\n",
      "\n",
      "epoch 5, loss = 0.6889\n",
      "Checking accuracy on test set\n",
      "Got 7468 / 10000 correct (74.68%)\n",
      "\n",
      "epoch 6, loss = 0.6384\n",
      "Checking accuracy on test set\n",
      "Got 7649 / 10000 correct (76.49%)\n",
      "\n",
      "epoch 7, loss = 0.5920\n",
      "Checking accuracy on test set\n",
      "Got 7672 / 10000 correct (76.72%)\n",
      "\n",
      "epoch 8, loss = 0.5421\n",
      "Checking accuracy on test set\n",
      "Got 7654 / 10000 correct (76.54%)\n",
      "\n",
      "epoch 9, loss = 0.5142\n",
      "Checking accuracy on test set\n",
      "Got 7798 / 10000 correct (77.98%)\n",
      "\n",
      "epoch 10, loss = 0.4685\n",
      "Checking accuracy on test set\n",
      "Got 7939 / 10000 correct (79.39%)\n",
      "\n",
      "epoch 11, loss = 0.4444\n",
      "Checking accuracy on test set\n",
      "Got 7962 / 10000 correct (79.62%)\n",
      "\n",
      "epoch 12, loss = 0.4124\n",
      "Checking accuracy on test set\n",
      "Got 7964 / 10000 correct (79.64%)\n",
      "\n",
      "epoch 13, loss = 0.3816\n",
      "Checking accuracy on test set\n",
      "Got 8068 / 10000 correct (80.68%)\n",
      "\n",
      "epoch 14, loss = 0.3562\n",
      "Checking accuracy on test set\n",
      "Got 8056 / 10000 correct (80.56%)\n",
      "\n",
      "epoch 15, loss = 0.3281\n",
      "Checking accuracy on test set\n",
      "Got 7963 / 10000 correct (79.63%)\n",
      "\n",
      "epoch 16, loss = 0.3015\n",
      "Checking accuracy on test set\n",
      "Got 8114 / 10000 correct (81.14%)\n",
      "\n",
      "epoch 17, loss = 0.2785\n",
      "Checking accuracy on test set\n",
      "Got 8097 / 10000 correct (80.97%)\n",
      "\n",
      "epoch 18, loss = 0.2708\n",
      "Checking accuracy on test set\n",
      "Got 7979 / 10000 correct (79.79%)\n",
      "\n",
      "epoch 19, loss = 0.2564\n",
      "Checking accuracy on test set\n",
      "Got 8070 / 10000 correct (80.70%)\n",
      "\n",
      "epoch 20, loss = 0.2325\n",
      "Checking accuracy on test set\n",
      "Got 8176 / 10000 correct (81.76%)\n",
      "\n",
      "epoch 21, loss = 0.1612\n",
      "Checking accuracy on test set\n",
      "Got 8353 / 10000 correct (83.53%)\n",
      "\n",
      "epoch 22, loss = 0.1286\n",
      "Checking accuracy on test set\n",
      "Got 8410 / 10000 correct (84.10%)\n",
      "\n",
      "epoch 23, loss = 0.1100\n",
      "Checking accuracy on test set\n",
      "Got 8367 / 10000 correct (83.67%)\n",
      "\n",
      "epoch 24, loss = 0.0989\n",
      "Checking accuracy on test set\n",
      "Got 8361 / 10000 correct (83.61%)\n",
      "\n",
      "epoch 25, loss = 0.0892\n",
      "Checking accuracy on test set\n",
      "Got 8355 / 10000 correct (83.55%)\n",
      "\n",
      "epoch 26, loss = 0.0783\n",
      "Checking accuracy on test set\n",
      "Got 8367 / 10000 correct (83.67%)\n",
      "\n",
      "epoch 27, loss = 0.0725\n",
      "Checking accuracy on test set\n",
      "Got 8385 / 10000 correct (83.85%)\n",
      "\n",
      "epoch 28, loss = 0.0645\n",
      "Checking accuracy on test set\n",
      "Got 8384 / 10000 correct (83.84%)\n",
      "\n",
      "epoch 29, loss = 0.0581\n",
      "Checking accuracy on test set\n",
      "Got 8389 / 10000 correct (83.89%)\n",
      "\n",
      "epoch 30, loss = 0.0544\n",
      "Checking accuracy on test set\n",
      "Got 8382 / 10000 correct (83.82%)\n",
      "\n",
      "epoch 31, loss = 0.0502\n",
      "Checking accuracy on test set\n",
      "Got 8355 / 10000 correct (83.55%)\n",
      "\n",
      "epoch 32, loss = 0.0478\n",
      "Checking accuracy on test set\n",
      "Got 8408 / 10000 correct (84.08%)\n",
      "\n",
      "epoch 33, loss = 0.0458\n",
      "Checking accuracy on test set\n",
      "Got 8377 / 10000 correct (83.77%)\n",
      "\n",
      "epoch 34, loss = 0.0427\n",
      "Checking accuracy on test set\n",
      "Got 8383 / 10000 correct (83.83%)\n",
      "\n",
      "epoch 35, loss = 0.0402\n",
      "Checking accuracy on test set\n",
      "Got 8423 / 10000 correct (84.23%)\n",
      "\n",
      "epoch 36, loss = 0.0363\n",
      "Checking accuracy on test set\n",
      "Got 8383 / 10000 correct (83.83%)\n",
      "\n",
      "epoch 37, loss = 0.0334\n",
      "Checking accuracy on test set\n",
      "Got 8402 / 10000 correct (84.02%)\n",
      "\n",
      "epoch 38, loss = 0.0333\n",
      "Checking accuracy on test set\n",
      "Got 8391 / 10000 correct (83.91%)\n",
      "\n",
      "epoch 39, loss = 0.0305\n",
      "Checking accuracy on test set\n",
      "Got 8393 / 10000 correct (83.93%)\n",
      "\n",
      "epoch 40, loss = 0.0302\n",
      "Checking accuracy on test set\n",
      "Got 8392 / 10000 correct (83.92%)\n",
      "\n",
      "epoch 41, loss = 0.0242\n",
      "Checking accuracy on test set\n",
      "Got 8418 / 10000 correct (84.18%)\n",
      "\n",
      "epoch 42, loss = 0.0206\n",
      "Checking accuracy on test set\n",
      "Got 8381 / 10000 correct (83.81%)\n",
      "\n",
      "epoch 43, loss = 0.0200\n",
      "Checking accuracy on test set\n",
      "Got 8381 / 10000 correct (83.81%)\n",
      "\n",
      "epoch 44, loss = 0.0182\n",
      "Checking accuracy on test set\n",
      "Got 8377 / 10000 correct (83.77%)\n",
      "\n",
      "epoch 45, loss = 0.0174\n",
      "Checking accuracy on test set\n",
      "Got 8435 / 10000 correct (84.35%)\n",
      "\n",
      "epoch 46, loss = 0.0170\n",
      "Checking accuracy on test set\n",
      "Got 8396 / 10000 correct (83.96%)\n",
      "\n",
      "epoch 47, loss = 0.0165\n",
      "Checking accuracy on test set\n",
      "Got 8397 / 10000 correct (83.97%)\n",
      "\n",
      "epoch 48, loss = 0.0172\n",
      "Checking accuracy on test set\n",
      "Got 8392 / 10000 correct (83.92%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rsp/anaconda3/envs/ml/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/rsp/anaconda3/envs/ml/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/rsp/anaconda3/envs/ml/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/rsp/anaconda3/envs/ml/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rsp/anaconda3/envs/ml/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/rsp/anaconda3/envs/ml/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/rsp/anaconda3/envs/ml/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/rsp/anaconda3/envs/ml/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/rsp/anaconda3/envs/ml/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/rsp/anaconda3/envs/ml/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/rsp/anaconda3/envs/ml/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/rsp/anaconda3/envs/ml/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/rsp/anaconda3/envs/ml/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/rsp/anaconda3/envs/ml/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/rsp/anaconda3/envs/ml/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/rsp/anaconda3/envs/ml/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-05bb3a9a0fac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# drop_out = [0.5, 0.75]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# for lr in learning_rates:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-587d50b5886d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(lr, bs, mo, epochs)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 计算loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#　反向传播\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 更新参数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rates = [0.01, 0.003]\n",
    "batch_sizes = [64, 128, 256, 512]\n",
    "momentum = [0.9, 0.95, 0.99]\n",
    "# drop_out = [0.5, 0.75]\n",
    "\n",
    "train(0.001, 64, 0.9)\n",
    "\n",
    "# for lr in learning_rates:\n",
    "#     for bs in batch_sizes:\n",
    "#         for mo in momentum:\n",
    "#             train(lr, bs, mo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
